# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
# Url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# Path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: "CPU"
enable_profiling: False

# ==============================================================================
# Training options
train_stage: "base"
is_distributed: 0

# dataset related
data_dir: "/cache/data/face_recognition_dataset/train_dataset/"
num_classes: 1
per_batch_size: 64
need_modelarts_dataset_unzip: True

# network structure related
backbone: "r100"
use_se: 1
emb_size: 512
act_type: "relu"
fp16: 1
pre_bn: 1
inference: 0
use_drop: 1
nc_16: 1

# loss related
margin_a: 1.0
margin_b: 0.2
margin_m: 0.3
margin_s: 64

# optimizer related
lr: 0.01
lr_scale: 1
lr_epochs: "8,14,18"
weight_decay: 0.0002
momentum: 0.9
max_epoch: 20
pretrained: ""
warmup_epochs: 0

# distributed parameter
local_rank: 0
world_size: 1
model_parallel: 0

# logging related
log_interval: 100
ckpt_path: "outputs"
max_ckpts: -1
dynamic_init_loss_scale: 65536
ckpt_steps: 1000

# export option
batch_size: 16
file_name: "fr.midnir"
file_format: "MINDIR"
export_pre_bn: 0
export_inference: 1
export_use_se: 0
export_emb_size: 256
export_act_type: "relu"
export_backbone: "r100"
export_use_drop: 0
head: "0"

---

# Help description for each configuration
enable_modelarts: "Whether training on modelarts, default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of the input data."
output_path: "The location of the output file."
device_target: 'Target device type'
enable_profiling: 'Whether enable profiling while training, default: False'

train_stage: "Train stage, base or beta"
is_distributed: "If multi device"

# export option
batch_size: "batch size"
file_name: "file name"
file_format: "file format, choices in ['MINDIR', 'AIR']"
export_pre_bn: "1: bn-conv-bn-conv-bn, 0: conv-bn-conv-bn"
export_inference: "use inference backbone"
export_use_se: "use se block or not"
export_emb_size: "embedding size of the network"
export_act_type: "activation layer type"
export_backbone: "backbone network"
export_use_drop: "whether use dropout in network"
head: "head type, default is 0"