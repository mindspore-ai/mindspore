relu_grad:
    description: |
        Computes gradient for the ReLU activation.

            Args:
                y_backprop (Tensor): Input gradients tensor,ã€€has the same dtype and shape as `x`.
                x (Tensor): Origin input tensor.

            Returns:
                Tensor, has the same dtype and shape as `x`.
