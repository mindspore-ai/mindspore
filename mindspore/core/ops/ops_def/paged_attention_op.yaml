#operator paged_attention
paged_attention:
  args:
    query:
      dtype: tensor
    key_cache:
      dtype: tensor
    value_cache:
      dtype: tensor
    block_tables:
      dtype: tensor
    context_lens:
      dtype: tensor
    antiquant_scale:
      dtype: tensor
      default: None
    antiquant_offset:
      dtype: tensor
      default: None
    head_num:
      dtype: int
      prim_init: True
    scale_value:
      dtype: float
      prim_init: True
    kv_head_num:
      dtype: int
      prim_init: True

  returns:
    attention_out:
      dtype: tensor
  function:
    disable: True
