# [first column]:model_name, If you need input shape, please connect it through ';1;' after the model name, where '1' is the input num.
# [second column]:accuracy limit in arm64
mobilenet_v1_1.0_224.tflite
mobilenet_v2_1.0_224.tflite
resnet.tflite
squeezenet.tflite
mtk_AADB_HADB_MBV2_model_fp32.tflite
hiai_cn_recognize_modify_padv2.tflite
hiai_cv_focusShootOCRModel_08.tflite
hiai_model_normalize_object_scene_ps_20200519.tflite
inception_v3.tflite
mtk_age_gender_fp16.tflite
mtk_isface.tflite
mtk_landmark.tflite
mtk_new_detect.tflite
mtk_pose.tflite
mtk_model_emotions_0727_nosoftmax.tflite
mtk_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite
mtk_276landmark_0913.tflite
mtk_face_recognition.tflite
mtk_convert_model.tflite
mtk_model_face_dress_fp16.tflite
detection_retinaface_fix
landmark
PoseNet_dla_17_x512_tmp
age_new
plat_isface
Q_hand_0812.pb
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid.pb
Q_AADB_HADB_MBV2_model.tflite
Q_convert.tflite
Q_crnn_ori_75w_slim_norm_pb2tflite.tflite
Q_crnn_ori_v2_405001_notrans_nopre_pb2tflite.tflite
Q_crnn_screen_slim400w_more_20w_pb2tflite.tflite
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid_tflite.tflite
Q_focusocr_cn_recog.tflite
Q_focusocr_jk_recog.tflite
Q_inception-249970-672-11-16_pb2tflite.tflite
Q_isface.tflite
Q_landmark.tflite
Q_language_model_hrmini_Q4_b4_17w.tflite
Q_new_detect.tflite
Q_object_scene.tflite
Q_pose.tflite
matmul.pb
add_uint8.tflite;2
mtk_face_features_v3.onnx
hdc_Face_Landmark5_MTI_Aesthetic.onnx
inception_v3.pb;1;1,299,299,3
mobilenet_v1_0.25_128_frozen.pb;1;1,128,128,3
mobilenet_v2_1.0_224_frozen.pb;1;1,224,224,3
ml_face_openclose.pb;1;1,32,32,3
hiai_AADB_HADB_MBV2_model.pb;1;1,224,224,3
hiai_model_0909_kd_rot_ps_softmax.pb;1;1,224,224,3
model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3
mtk_AADB_HADB_MBV2_model.pb;1;1,224,224,3
mtk_AADB_HADB_MBV3_model.pb;1;1,224,224,3
mtk_model_face_dress.pb;1;1,128,128,3
hiai_model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3
hiai_label_and_video.pb;1;1,224,224,3
tinyyolov2-8.onnx;1;1,416,416,3
mtk_detect-mbv2-shortcut-400-400-simplified.onnx
emotion-ferplus-8.onnx
rcnn-ilsvrc13-9.onnx
shufflenet-v2-10.onnx
squeezenet1.1-7.onnx
ml_table_detection_fp32_tmp.onnx
ml_table_segment.onnx
googlenet-9.onnx
inception-v1-9.onnx
shufflenet-9.onnx
ml_face_3d.onnx
gts_version-RFB-320_simplified.onnx
mnist-8.onnx
ml_video_edit_judge.onnx
ml_video_edit_vignet.onnx
hdc_mobilenet_1w_class.onnx
ml_video_edit_imitate_filter.onnx
ml_edu_kit_hand_detection.onnx
ml_edu_kit_hand_key_position.onnx
mtk_detect-deeper-halfdeeper-mbv1-shortcut-400-400_nopostprocess_simplified_onnx.onnx
mtk_detect-mbv1-shortcut-400-400_nopostprocess_simplified_onnx.onnx
mtk_detect-deeper-halfdeeper-mbv1-lastearlySSD-shortcut-400-400_nopostprocess_simplified_onnx.onnx
ml_2012_ocr_detection_tmp.onnx
ml_video_edit_enhance_update_tmp.onnx
bloom_hongmo_detection_tmp.onnx
Q_face_recognition.onnx
Q888_iris_detect.onnx
ml_ocr_bank_card_detection_inception_tmp
ml_ocr_detect_20200305
Q_iMaxDN_RGB_385_p_RGB_RGB_pb2tflite.tflite
Q_iMaxSR_RGB_385_p_pb2tflite.tflite
mtk_age_gender.pb
mtk_model_ckpt.pb
Q_inception-249970-672-11-16.pb
Q_crnn_screen_slim400w_more_20w.pb
hiai_ssd_mobilenetv2_object.pb
hiai_humanDetection.pb
mtk_face_features_v1.pb
Q_crnn_ori_75w_slim_norm.pb
Q_crnn_ori_v2_405001_notrans_nopre.pb
bolt_segment.pb
ml_location_lane_counter.onnx 2
gts_detect_5k_tf115.tflite
smartreply.tflite
ml_text_correction.tflite
ml_ocr_jk_pb2tflite.tflite
scan_hms_angle_pb2tflite.tflite
scan_hms_detect_pb2tflite.tflite
ml_face_openclose_tflite.tflite
unet_mbv2_05_104pts.tflite
hiai_AADB_HADB_MBV2_model_f16.tflite
hiai_AADB_HADB_MBV2_model_fp32.tflite
hiai_detect_curve_model_float32.tflite
hiai_detectmodel_06_23_960_480_1180700.tflite
lite-model_aiy_vision_classifier_food_V1_1.tflite
lite-model_disease-classification_1.tflite
lite-model_models_mushroom-identification_v1_1.tflite
smartreply_1_default_1.tflite
text_classification.tflite
Q_detect_fpn_add_inception-1448650.tflite
Q_hand_0812_pb2tflite.tflite
bloom_landmark.tflite
Q888_face_dress_mv3y.tflite
Q888_HADB_AADB_MBV2_model_fp32.tflite
Q888_landmark.tflite
Q888_pose.tflite
Q888_lapa158_unet_0924.tflite
Q888_isface.tflite
Q888_new_detect.tflite
Q888_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite
Q888_face_emo_dress_mv3_orderd.tflite
hdc_age_medium
hdc_contour_pose_128
hdc_emotion
hdc_fivembnet
hdc_isface
hdc_mobilenetface
hdc_retinaface
hdc_resnet
mtk_model_normalize_object_scene_ps_20200519_f32.tflite
hiai_cpu_face_emotion.pb
hiai_cpu_face_gazing.pb
hiai_cpu_face_headpose.pb
hiai_ctpn_feature_map.pb
hiai_cv_focusShootOCRModel_02.pb
hiai_cv_focusShootOCRModel_08.pb
hiai_cv_poseEstimation.pb
hiai_detectmodel_06_23_960_480_1180700.pb
hiai_face_model_npu.pb
hiai_iMaxDN_RGB.pb
hiai_iMaxSR_RGB.pb
hiai_lm_inference_graph.pb
hiai_PoseEstimation_Pcm.pb
hiai_model_0909_kd_rot_ps_softmax.tflite
hiai_chinese_english_recognize_model_float32.tflite
hiai_bigmodel_ghost_2_1_no_normalized_no_trans_tflite.tflite
hiai_bigmodel_ghost_5_1_no_normalized_no_trans_tflite.tflite
hiai_detectmodel_desnet_256_128_64_32.tflite
mtk_AADB_HADB_MBV3_model_fp32.tflite
Q888_face_recognition.onnx
mobilenet_v1_0.25_128.tflite
mobilenet_v1_0.5_160.tflite
mobilenet_v1_0.75_192.tflite
mobilenet_v1_1.0_160.tflite
mtk_model_ckpt.tflite
mtk_age_gender.tflite
mtk_model_face_dress.tflite
mtk_face_features_v1.tflite
mtk_isface
mtk_landmark
mtk_pose_tuku
mtk_face_recognition_v1
mtk_2012_ATLANTA_10class_20190614_v41
mtk_detect-deeper-halfdeeper-mbv1-lastearlySSD-shortcut-400-400_nopostprocess_simplified
mtk_detect-mbv1-shortcut-400-400_nopostprocess_simplified
mtk_detect_mbv1_640_480_nopostprocess_simplified
densenet.tflite
resnet_v2_101_299.tflite
mnasnet_1.3_224.tflite
deeplabv3_257_mv_gpu.tflite
multi_person_mobilenet_v1_075_float.tflite
ide_label_base.tflite
ml_ei_headpose.tflite
mnist.tflite
mobilenet.tflite
scan_hms_angle1.tflite
scan_hms_detect.tflite
ml_ocr_jk.tflite
nasnet_mobile.tflite
nasnet_large.tflite
model_emotions_0727_nosoftmax.tflite
inception_resnet_v2.tflite
hiai_PoseEstimation_Pcm.tflite
hiai_ssd_mobilenetv2_object.tflite
hiai_cv_focusShootOCRModel_02.tflite
hiai_cv_poseEstimation.tflite
inception_v4.tflite
mtk_model_normalize_object_scene_ps_20200519_f16.tflite
mtk_AADB_HADB_MBV2_model_f16.tflite
mtk_AADB_HADB_MBV3_model_f16.tflite
mtk_model_emotions_0725_fp16.tflite
mtk_face_features_v1_fp16.tflite
Q888_age_gender_orderd.tflite
emotion
gender_res_large_deploy
glasses
hat
isface
ml_bank_detect_0312_tmp
ml_face_div_parsing
ml_hardware_eyeclose
Mnet6_0312_extract_pay
pose_3d
hiai_face_RFB-Epoch-170-no-transpose
tracking
detect-deeper-halfdeeper-mbv1-shortcut-400-400_nopostprocess_simplified
hiai_face_detect_rfb
hiai_face_isface
hiai_face_landmark
hiai_face_pose_tuku
ml_hand_detection
ml_ocr_sfz_detect_0325_tmp
ml_hardware_liveness
ml_liveness_detect_landmark_tmp
ml_face_contour
2012_ATLANTA_1class_20190621_v4.x_nomean
ml_ocr_sfz_add_final_0325
ml_hardware_pose
ml_bank_recog
2012_ATLANTA_10class_20190131_v4.0
mnet
recognition
ml_face_landmark
model_hebing_3branch
hiai_cv_focusShootOCRModel_07
hiai_cv_focusShootOCRModel_03
hiai_cv_focusShootOCRModel_01
hiai_face_hat1
hiai_cv_focusShootOCRModel_04
hiai_cv_focusShootOCRModel_06
hiai_cpu_face_hat
hiai_video_seg
hiai_semantic_seg
hiai_human_seg
hiai_face_recognition_1
hiai_cpu_face_detect
hiai_cpu_face_attr
hiai_face_attr1
retinaface
deconvs_model
ml_location_scene_division
ml_tabel_recog
6c_seg_nomean_20200610
ml_video_edit_img_segment
ml_video_edit_video_segment_gauss_adaptis_part1
ml_video_edit_Mnet
ml_video_edit_detect
ml_video_edit_MnetN367_extract_1010_pay
ml_video_edit_person_divison_pic
ml_video_edit_reid
ml_video_edit_v10_best_model_nomean_20200723
inception-v2-9.onnx
ml_pic_shopping.tflite
ml_ocr_latin.tflite;1;1,32,512,1 10
CloudBU_FSRCNN_RTC_8ch_3450_QP9.onnx;1;1,225,225,3
CloudBU_rfdn_rtc_x2_ver2_13.onnx;1;1,225,225,3
CloudBU_rfdn_rtc_x2_ver2_3450.onnx;1;1,225,225,3 0.7
hiai_asr_last_e1_cpu_fast_wavenet_batch1_frame1_one_cache_fp32.tflite;2
hiai_asr_last_e1_cpu_fast_wavenet_batch1_frame1_one_cache.pb;2
