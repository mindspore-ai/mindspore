# [first column]:model_name, If you need input shape, please connect it through ';1;' after the model name, where '1' is the input num.
# [second column]:accuracy limit in arm64
mobilenet_v2_1.0_224.tflite
mtk_age_gender_fp16.tflite
mtk_new_detect.tflite
mtk_model_emotions_0727_nosoftmax.tflite
Q_AADB_HADB_MBV2_model.tflite
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid_tflite.tflite
Q_inception-249970-672-11-16_pb2tflite.tflite
Q_isface.tflite
Q_language_model_hrmini_Q4_b4_17w.tflite
Q_new_detect.tflite
Q_object_scene.tflite
Q_iMaxDN_RGB_385_p_RGB_RGB_pb2tflite.tflite
Q_iMaxSR_RGB_385_p_pb2tflite.tflite
Q_detect_fpn_add_inception-1448650.tflite
Q888_face_dress_mv3y.tflite
Q888_HADB_AADB_MBV2_model_fp32.tflite
Q888_landmark.tflite
Q888_pose.tflite
Q888_isface.tflite
Q888_new_detect.tflite
Q888_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite
Q888_face_emo_dress_mv3_orderd.tflite
mtk_AADB_HADB_MBV2_model_fp32.tflite
mtk_age_gender.tflite
mtk_model_face_dress.tflite
mtk_model_normalize_object_scene_ps_20200519_f16.tflite
mtk_AADB_HADB_MBV2_model_f16.tflite
mtk_model_emotions_0725_fp16.tflite
# Q888_age_gender_orderd.tflite's precision deteriorates in P50
Q888_age_gender_orderd.tflite;1:input 9
ml_ocr_latin.tflite;1;1,32,512,1 10
mtk_AADB_HADB_MBV2_model_fp32.tflite;1:input_0 3
resnet.tflite
squeezenet.tflite
# hiai_cn_recognize_modify_padv2.tflite's precision deteriorates in P50
hiai_cn_recognize_modify_padv2.tflite 10
hiai_model_normalize_object_scene_ps_20200519.tflite 18
inception_v3.tflite
mtk_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite 29
mtk_276landmark_0913.tflite 7
mtk_face_recognition.tflite 8
mtk_convert_model.tflite
mtk_model_face_dress_fp16.tflite
Q_convert.tflite 9
#Q_crnn_ori_75w_slim_norm_pb2tflite.tflite's precision deteriorates in P50
Q_crnn_ori_75w_slim_norm_pb2tflite.tflite 23
#Q_crnn_ori_v2_405001_notrans_nopre_pb2tflite.tflite's precision deteriorates in P50
Q_crnn_ori_v2_405001_notrans_nopre_pb2tflite.tflite 33
Q_crnn_screen_slim400w_more_20w_pb2tflite.tflite 38
Q_focusocr_cn_recog.tflite 24
Q_focusocr_jk_recog.tflite 15
add_uint8.tflite;2
gts_detect_5k_tf115.tflite
smartreply.tflite
ml_text_correction.tflite
ml_ocr_jk_pb2tflite.tflite
scan_hms_angle_pb2tflite.tflite
scan_hms_detect_pb2tflite.tflite 16
ml_face_openclose_tflite.tflite
unet_mbv2_05_104pts.tflite 8
hiai_AADB_HADB_MBV2_model_f16.tflite
hiai_AADB_HADB_MBV2_model_fp32.tflite
hiai_detect_curve_model_float32.tflite
smartreply_1_default_1.tflite
text_classification.tflite
mobilenet_v1_0.25_128.tflite
hiai_latin_ocr.tflite;1:input_0 30
hiai_latin_ocr_1.tflite;1:input_0 13
siteAI_digcom_g2v_keras.tflite;1:conv2d_1_input
siteAI_trans_nonlinear.tflite;1:features_placeholder
siteAI_trans_tcpclassify.tflite;1:conv2d_1_input
siteAI_wireless_depress_w.tflite;1:x-input 8
siteAI_wireless_restore_w.tflite;1:x-input
magenta_arbitrary-image-stylization-v1-256_fp16_prediction_1.tflite;1:style_image
hiai_cpu_face_emotion.tflite;1:input_0
hiai_cpu_face_gazing.tflite;1:input_0
hiai_cpu_face_headpose.tflite;1:input_0
hiai_humanDetection.tflite;1:normalized_input_image_tensor 11
ml_face_openclose.tflite;1:input
hiai_face_model_npu.tflite;1:input_0
hiai_ctpn_feature_map.tflite;1:input_image
hiai_cv_labelDetectorModel_v2.tflite;1:input_0 17
hiai_cv_labelDetectorModel_v4.tflite;1:input_0
hiai_dress_detect.tflite;1:data
hiai_cv_saliencyDetectorModel.tflite;1:image_tensor
hiai_frozen_inference_graph.tflite;1:image_tensor
hiai_ghostnet.tflite;1:input
hiai_label_and_video.tflite;1:input_0 7
hiai_lm_inference_graph.tflite;1:image_tensor
efficientnet_lite0_fp32_2.tflite;1:images
mnasnet_0.50_224_1_metadata_1.tflite;1:input
posenet_mobilenet_float_075_1_default_1.tflite;1:sub_2 39
deeplabv3_1_default_1.tflite;1:sub_7
lite-model_arbitrary-image-stylization-inceptionv3_fp16_predict_1.tflite;1:style_image
mindspore_text_classification_tflite.tflite;1:base_input
ml_ocr_latin_pb2tflite.tflite;1:input_0 9
ml_location.tflite;1:inputs
bloom_new_detect.tflite;1:input
bloom_model_age_gender.tflite;1:input
hiai_object_detect_814.tflite;1:normalized_input_image_tensor 10
hiai_object_tflite_graph_8bit.tflite;1:normalized_input_image_tensor
lma_tsec_shallow_channels16_ds2.1.1_model-best-f1.tflite;1:inputs
ml_video_edit_img_segment_adaptise_pb2tflite.tflite;2:backbone_features2,w 12
hiai_cv_labelDetectorModel_v3.tflite;2:input_0,input_1
ml_headpose_pb2tflite.tflite;3:input_1,batch_normalization_8/batchnorm/add,batch_normalization_1/batchnorm/add;1,64,64,3:16:16
ml_ei_headpose_pb2tflite.tflite;3:input_1,batch_normalization_8/batchnorm_1/add,batch_normalization_1/batchnorm_1/add;1,64,64,3:16:16
#lite-model_mobilebert_1_metadata_1.tflite's precision deteriorates in P50
lite-model_mobilebert_1_metadata_1.tflite;3:input_ids,input_mask,segment_ids 23
coco_ssd_mobilenet_v1_1.0.tflite
mtk_AADB_HADB_MBV3_model_fp32.tflite;1:input_0
densenet.tflite;1:Placeholder
resnet_v2_101_299.tflite;1:input
deeplabv3_257_mv_gpu.tflite;1:sub_7
ml_ei_headpose.tflite;1:input_1
mnist.tflite;1:conv2d_input
mobilenet.tflite;1:conv2d_input
ml_ocr_jk.tflite;1:input_0
nasnet_mobile.tflite;1:input
nasnet_large.tflite;1:input
model_emotions_0727_nosoftmax.tflite;1:input
inception_v4.tflite;1:input
