screenshot_direction.pb;1:input_1;1,64,512,3;;online_convert
screenshot_angle.pb;1:input_images;1,1024,1024,3;;online_convert 3.0
screenshot_ocr_220613_batch32_textlen24.pb;1:img_data;1,32,256,3;;online_convert
unet_model_reconstruct.pb;1:content;1,256,256,3;;online_convert
ml_video_edit_generate_filter.pb;1:lowres_input;;;online_convert
densenet.pb;1:Placeholder;1,224,224,3;;online_convert
inception_resnet_v2.pb;1:input;1,299,299,3;;online_convert
inception_v3.pb;1:input;1,299,299,3;;online_convert
inception_v4.pb;1:input;1,299,299,3;;online_convert
mnasnet_1.0_224.pb;1:input;;;online_convert
mnasnet_1.3_224.pb;1:input;;;online_convert
mobilenet_v1_0.25_128_frozen.pb;1:input;1,128,128,3;;online_convert
mobilenet_v2_1.0_224_frozen.pb;1:input;1,224,224,3;;online_convert
nasnet_large.pb;1:input;1,331,331,3;;online_convert
nasnet_mobile.pb;1:input;1,224,224,3;;online_convert
squeezenet.pb;1:Placeholder;1,224,224,3;;online_convert
ml_ei_headpose.pb;1:input_1;1,64,64,3;;online_convert
ml_ei_landmark.pb;1:input_image;1,160,160,3;;online_convert
ml_face_openclose.pb;1:input;1,32,32,3;;online_convert
ml_object_detect.pb;1:input/input_data;1,288,288,3;;online_convert
ml_ocr_jk.pb;1:input_0;;;online_convert
ml_video_edit_enhance.pb;1:lowres_input;;;online_convert
ml_vision_guide_detection1.pb;1:input/input_data;;;online_convert
ml_vision_guide_detection3.pb;1:input/input_data;;;online_convert
scan_hms_angle.pb;1:normalized_input_image_tensor;;;online_convert
scan_hms_detect.pb;1:normalized_input_image_tensor;;;online_convert
hiai_AADB_HADB_MBV2_model.pb;1:input_0;1,224,224,3;;online_convert
hiai_cn_recognize_modify_padv2.pb;1:input_0;1,32,512,1
hiai_cpu_face_emotion.pb;1:input_0;;;online_convert
hiai_cpu_face_gazing.pb;1:input_0;;;online_convert
hiai_cpu_face_headpose.pb;1:input_0;;;online_convert
hiai_ctpn_feature_map.pb;1:input_image
hiai_cv_focusShootOCRModel_08.pb;1:input
hiai_cv_poseEstimation.pb;1:Image
hiai_detectmodel_06_23_960_480_1180700.pb;1:input
hiai_dress_detect.pb;1:data;1,960,960,3
hiai_face_model_npu.pb;1:input_0
hiai_frozen_inference_graph.pb;1:image_tensor;1,300,300,3
hiai_ghostnet.pb;1:input
hiai_iMaxDN_RGB.pb;1:input
hiai_iMaxSR_RGB.pb;1:input
hiai_label_and_video.pb;1:input_0;1,224,224,3
hiai_latin_ocr_1.pb;1:input_0
hiai_lm_inference_graph.pb;1:image_tensor
hiai_model_0909_kd_rot_ps_softmax.pb;1:input_0;1,224,224,3
hiai_PoseEstimation_Pcm.pb;1:image
hiai_model_0909_kd_rot_ps_softmax.tflite;1:input_0
hiai_chinese_english_recognize_model_float32.tflite;1:input_0
hiai_bigmodel_ghost_2_1_no_normalized_no_trans_tflite.tflite;1:input_0
hiai_bigmodel_ghost_5_1_no_normalized_no_trans_tflite.tflite;1:input_0
hiai_cn_recognize_modify_padv2.tflite;1:input_0
hiai_model_normalize_object_scene_ps_20200519.tflite;1:input_0
mtk_AADB_HADB_MBV2_model_fp32.tflite;1:input_0
mtk_AADB_HADB_MBV3_model_fp32.tflite;1:input_0
mobilenet_v1_0.25_128.tflite;1:input
mobilenet_v2_1.0_224.tflite;1:input
mtk_model_normalize_object_scene_ps_20200519_f32.tflite;1:input_0
mtk_model_ckpt.tflite;1:input
mtk_age_gender.tflite;1:img
mtk_model_face_dress.tflite;1:input
mtk_face_features_v1.tflite;1:input
ml_ei_headpose.pb;1:input_1;1,64,64,3;;parallel_predict
hiai_AADB_HADB_MBV2_model.pb;1:input_0;1,224,224,3;;parallel_predict
hiai_dress_detect.pb;1:data;1,960,960,3;;parallel_predict
hiai_cn_recognize_modify_padv2.pb;1:input_0;1,32,512,1;;parallel_predict
inception_v4.pb;1:input;1,299,299,3;;parallel_predict
mobilenet_v1_0.25_128_frozen.pb;1:input;1,128,128,3;;parallel_predict
inception_v3.pb;1:input;1,299,299,3;;parallel_predict
hiai_label_and_video.pb;1:input_0;1,224,224,3;;parallel_predict
hiai_model_0909_kd_rot_ps_softmax.pb;1:input_0;1,224,224,3;;parallel_predict
screenshot_angle.pb;1:input_images;1,1024,1024,3;;parallel_predict 3.0
ml_object_detect.pb;1:input/input_data;1,288,288,3;;parallel_predict

#parallel predict
poisson_model.pb;4;800,1:800,1:800,217:800,1;;parallel_predict 0.5
browser_deepfm_v7.pb;2;200,94:200,94;;parallel_predict;DEFAULT;_graph 0.5
browser_deepfm_v7_int64.pb;2;200,94:200,94;;parallel_predict;INT64;_graph 0.5
dcn_114_int64.pb;65;1,50:1,50:1,50:1,50:1,50:1,50:1,50:1,1:1,50:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,5:1,5:1,5:1,5:1,5:1,5:1,29:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,10:1,20:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1;;parallel_predict;INT64 0.00003
browser_v50_int64.pb;2;75,276:75,276;;parallel_predict;INT64 0.5
browser_v79.pb;2;10,294:10,294;;parallel_predict;INT64 0.004
bert_mindir.mindir;3;1,128:1,128:1,128;;parallel_predict 2.5
wide_deep_model_weight16000_2.pb;2;16000,39:16000,39;;parallel_predict 0.5
roberta_minir_graph.mindir;1;1,32;;parallel_predict;DEFAULT;_graph 53
browser_scene1_v2.pb;1;75,19910;;parallel_predict 0.5
LaBSE.onnx;2;1,32:1,32;;parallel_predict;DEFAULT;_graph 5
dcn_114.pb;65;1,50:1,50:1,50:1,50:1,50:1,50:1,50:1,1:1,50:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,5:1,5:1,5:1,5:1,5:1,5:1,29:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,10:1,20:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1:1,1;;parallel_predict 0.00003
browser_v7.pb;1;75,39160;;parallel_predict 0
browser_v15.pb;1;75,10896;;parallel_predict 0
browser_v36.pb;2;75,190:75,9120;;parallel_predict 0.00002
browser_v50.pb;2;75,276:75,276;;parallel_predict 0.5
browser_v58.pb;1;75,26180;;parallel_predict 0
browser_v79_int32.pb;2;10,294:10,294;;parallel_predict 0.004
noah_206.pb;3;75,206:75,206:75,5;;parallel_predict 0.0002

#tf model from models_tf.cfg
mnasnet_1.0_224.pb;1:input;1,224,224,3;;parallel_predict 0.5
scan_hms_detect.pb;1:normalized_input_image_tensor;1,320,320,1;;parallel_predict 0.5
hiai_cpu_face_emotion.pb;1:input_0;1,224,224,1;;parallel_predict 0.5
hiai_cpu_face_headpose.pb;1:input_0;1,256,256,3;;parallel_predict 0.5
hiai_cv_focusShootOCRModel_02.pb;1:input_0;1,32,512,1;;parallel_predict 0.5
hiai_latin_ocr.pb;1:input_0;1,32,1024,1;;parallel_predict 0.5
deepaudio.onnx;1;5,80,80;;parallel_predict 0.5
sad_conformer4_output128lu512.pb;3;1,128512,1:1,397,128:1,199;;parallel_predict 0.5
