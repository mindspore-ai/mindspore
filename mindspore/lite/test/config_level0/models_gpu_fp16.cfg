mobilenet_v1_1.0_224.tflite
mobilenet_v2_1.0_224.tflite
mtk_age_gender_fp16.tflite
mtk_isface.tflite
mtk_landmark.tflite
mtk_new_detect.tflite
mtk_pose.tflite
mtk_model_emotions_0727_nosoftmax.tflite
landmark
PoseNet_dla_17_x512_tmp
plat_isface
ml_location_lane_counter.onnx 5.5
Q888_face_recognition.onnx
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid.pb
Q_AADB_HADB_MBV2_model.tflite
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid_tflite.tflite
Q_inception-249970-672-11-16_pb2tflite.tflite
Q_isface.tflite
Q_landmark.tflite
Q_language_model_hrmini_Q4_b4_17w.tflite
Q_new_detect.tflite
Q_object_scene.tflite
Q_pose.tflite
Q_face_recognition.onnx
Q888_iris_detect.onnx
Q_iMaxDN_RGB_385_p_RGB_RGB_pb2tflite.tflite
Q_iMaxSR_RGB_385_p_pb2tflite.tflite
Q_detect_fpn_add_inception-1448650.tflite
Q888_face_dress_mv3y.tflite
Q888_HADB_AADB_MBV2_model_fp32.tflite
Q888_landmark.tflite
Q888_pose.tflite
Q888_isface.tflite
Q888_new_detect.tflite
Q888_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite
Q888_face_emo_dress_mv3_orderd.tflite
mtk_detect-deeper-halfdeeper-mbv1-shortcut-400-400_nopostprocess_simplified_onnx.onnx
mtk_detect-mbv1-shortcut-400-400_nopostprocess_simplified_onnx.onnx
mtk_detect-deeper-halfdeeper-mbv1-lastearlySSD-shortcut-400-400_nopostprocess_simplified_onnx.onnx
inception_v3.pb;1;1,299,299,3 5
mobilenet_v1_0.25_128_frozen.pb;1;1,128,128,3 5
ml_face_openclose.pb;1;1,32,32,3 5
hiai_AADB_HADB_MBV2_model.pb;1;1,224,224,3 5
mtk_AADB_HADB_MBV2_model.pb;1;1,224,224,3 5
mtk_AADB_HADB_MBV3_model.pb;1;1,224,224,3 5
mtk_model_face_dress.pb;1;1,128,128,3 5
mtk_AADB_HADB_MBV2_model_fp32.tflite
mtk_detect-mbv2-shortcut-400-400-simplified.onnx
mtk_age_gender.pb
mtk_age_gender.tflite
mtk_model_face_dress.tflite
mtk_isface
mtk_landmark
mtk_pose_tuku
mtk_2012_ATLANTA_10class_20190614_v41
mtk_detect-deeper-halfdeeper-mbv1-lastearlySSD-shortcut-400-400_nopostprocess_simplified
mtk_detect_mbv1_640_480_nopostprocess_simplified
mtk_model_normalize_object_scene_ps_20200519_f16.tflite
mtk_AADB_HADB_MBV2_model_f16.tflite
mtk_model_emotions_0725_fp16.tflite
# Q888_age_gender_orderd.tflite's precision deteriorates in P50
Q888_age_gender_orderd.tflite 9
ml_ocr_latin.tflite;1;1,32,512,1 10
ml_ocr_detect_20200305;1;1,544,544,3 10
ml_face_3d.onnx
CloudBU_FSRCNN_RTC_8ch_3450_QP9.onnx;1;1,225,225,3 1.5
CloudBU_rfdn_rtc_x2_ver2_13.onnx;1;1,225,225,3 1.0
CloudBU_rfdn_rtc_x2_ver2_3450.onnx;1;1,225,225,3 108
Q888_CV_model_face_dress_mv3y.pb;1:input;1,112,112,3 4
mtk_AADB_HADB_MBV2_model_fp32.tflite;1:input_0 3
ml_location_lane_counter0.onnx;1:input
resnet.tflite
squeezenet.tflite
# hiai_cn_recognize_modify_padv2.tflite's precision deteriorates in P50
hiai_cn_recognize_modify_padv2.tflite 10
hiai_model_normalize_object_scene_ps_20200519.tflite 18
inception_v3.tflite
mtk_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite 29
mtk_276landmark_0913.tflite 7
mtk_face_recognition.tflite 8
mtk_convert_model.tflite
mtk_model_face_dress_fp16.tflite
detection_retinaface_fix 8
# age_new's precision deteriorates in P50
age_new 8
Q_convert.tflite 9
#Q_crnn_ori_75w_slim_norm_pb2tflite.tflite's precision deteriorates in P50
Q_crnn_ori_75w_slim_norm_pb2tflite.tflite 23
#Q_crnn_ori_v2_405001_notrans_nopre_pb2tflite.tflite's precision deteriorates in P50
Q_crnn_ori_v2_405001_notrans_nopre_pb2tflite.tflite 33
Q_crnn_screen_slim400w_more_20w_pb2tflite.tflite 31
Q_focusocr_cn_recog.tflite 24
Q_focusocr_jk_recog.tflite 14
matmul.pb
add_uint8.tflite;2
mtk_face_features_v3.onnx 7
hdc_Face_Landmark5_MTI_Aesthetic.onnx
mobilenet_v2_1.0_224_frozen.pb;1;1,224,224,3 6
hiai_model_0909_kd_rot_ps_softmax.pb;1;1,224,224,3 12
model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3 7
hiai_model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3 18
hiai_label_and_video.pb;1;1,224,224,3 16
tinyyolov2-8.onnx;1;1,416,416,3 11
emotion-ferplus-8.onnx
#rcnn-ilsvrc13-9.onnx's precision deteriorates in P50(has nan value)
#rcnn-ilsvrc13-9.onnx
shufflenet-v2-10.onnx
squeezenet1.1-7.onnx
ml_table_detection_fp32_tmp.onnx
ml_table_segment.onnx
shufflenet-9.onnx
gts_version-RFB-320_simplified.onnx
mnist-8.onnx
ml_video_edit_judge.onnx 12
ml_video_edit_vignet.onnx
hdc_mobilenet_1w_class.onnx 22
ml_edu_kit_hand_detection.onnx
ml_edu_kit_hand_key_position.onnx
ml_2012_ocr_detection_tmp.onnx
ml_video_edit_enhance_update_tmp.onnx
bloom_hongmo_detection_tmp.onnx
ml_ocr_bank_card_detection_inception_tmp 10
mtk_model_ckpt.pb 17
Q_inception-249970-672-11-16.pb 6
#Q_crnn_screen_slim400w_more_20w.pb's precision deteriorates in P50
Q_crnn_screen_slim400w_more_20w.pb 70
hiai_ssd_mobilenetv2_object.pb 38
hiai_humanDetection.pb 13
#mtk_face_features_v1.pb's precision deteriorates in P50
mtk_face_features_v1.pb 17
#Q_crnn_ori_75w_slim_norm.pb's precision deteriorates in P50
Q_crnn_ori_75w_slim_norm.pb 30
Q_crnn_ori_v2_405001_notrans_nopre.pb 23
ml_location_lane_counter.onnx 4
gts_detect_5k_tf115.tflite
smartreply.tflite
ml_text_correction.tflite
ml_ocr_jk_pb2tflite.tflite
scan_hms_angle_pb2tflite.tflite
scan_hms_detect_pb2tflite.tflite 16
ml_face_openclose_tflite.tflite
unet_mbv2_05_104pts.tflite 8
hiai_AADB_HADB_MBV2_model_f16.tflite
hiai_AADB_HADB_MBV2_model_fp32.tflite
hiai_detect_curve_model_float32.tflite
smartreply_1_default_1.tflite
text_classification.tflite
nasnet_large.pb;1:input;1,331,331,3
nasnet_mobile.pb;1:input;1,224,224,3
ml_ocr_jk.pb;1:input_0
ml_video_edit_enhance.pb;1:lowres_input
scan_hms_angle.pb;1:normalized_input_image_tensor
scan_hms_detect.pb;1:normalized_input_image_tensor 14
hiai_cn_recognize_modify_padv2.pb;1:input_0;1,32,512,1 14
hiai_dress_detect.pb;1:data;1,960,960,3
hiai_ghostnet.pb;1:input
hiai_latin_ocr.pb;1:input_0
mtk_model_normalize_object_scene_ps_20200519.pb;1:input_0;1,224,224,3 7
ml_ocr_latin.pb;1:input_0 8
siteAI_wireless_depress_w.pb;1:x-input;1,36
siteAI_wireless_restore_w.pb;1:x-input;1,36
siteAI_trans_nonlinear.pb;1:features_placeholder;1,137
siteAI_trans_nonlinear40g.pb;1:features_placeholder;1,271
siteAI_trans_nonlinear134g.pb;1:features_placeholder;1,137
siteAI_trans_nonlinear134g_nrz.pb;1:features_placeholder;1,182
ml_video_edit_img_segment_adaptise.pb;2:backbone_features2,w 12
hiai_transformer_encoder.pb;15:buffer_in_0,buffer_in_1,buffer_in_2,buffer_in_3,buffer_in_4,buffer_in_5,buffer_in_6,buffer_in_7,buffer_in_8,buffer_in_9,buffer_in_10,buffer_in_11,buffer_in_12,buffer_in_13,encoder_in_deploy
fsr_270_mindspore.pb
fsr_360_mindspore.pb
fsr_720_mindspore.pb
mobilenet_v1_0.25_160.tflite;1:input
mobilenet_v1_0.25_192.tflite;1:input
mobilenet_v1_0.25_224.tflite;1:input
mobilenet_v1_0.5_128.tflite;1:input
mobilenet_v1_0.5_192.tflite;1:input
mobilenet_v1_0.5_224.tflite;1:input
mobilenet_v1_0.75_128.tflite;1:input
mobilenet_v1_0.75_160.tflite;1:input
mobilenet_v1_0.75_224.tflite;1:input
mobilenet_v1_1.0_128.tflite;1:input 7
mobilenet_v1_1.0_192.tflite;1:input 6
hiai_latin_ocr.tflite;1:input_0 30
hiai_latin_ocr_1.tflite;1:input_0 13
siteAI_digcom_g2v_keras.tflite;1:conv2d_1_input
siteAI_trans_nonlinear.tflite;1:features_placeholder
siteAI_trans_tcpclassify.tflite;1:conv2d_1_input
siteAI_wireless_depress_w.tflite;1:x-input 8
siteAI_wireless_restore_w.tflite;1:x-input
magenta_arbitrary-image-stylization-v1-256_fp16_prediction_1.tflite;1:style_image
hiai_cpu_face_emotion.tflite;1:input_0
hiai_cpu_face_gazing.tflite;1:input_0
hiai_cpu_face_headpose.tflite;1:input_0
hiai_humanDetection.tflite;1:normalized_input_image_tensor 11
ml_face_openclose.tflite;1:input
hiai_face_model_npu.tflite;1:input_0
hiai_ctpn_feature_map.tflite;1:input_image
hiai_cv_labelDetectorModel_v2.tflite;1:input_0 17
hiai_cv_labelDetectorModel_v4.tflite;1:input_0
hiai_dress_detect.tflite;1:data
hiai_cv_saliencyDetectorModel.tflite;1:image_tensor
hiai_frozen_inference_graph.tflite;1:image_tensor
hiai_ghostnet.tflite;1:input
hiai_label_and_video.tflite;1:input_0 7
hiai_lm_inference_graph.tflite;1:image_tensor
efficientnet_lite0_fp32_2.tflite;1:images
efficientnet_lite1_fp32_2.tflite;1:images
efficientnet_lite2_fp32_2.tflite;1:images
efficientnet_lite3_fp32_2.tflite;1:images
efficientnet_lite4_fp32_2.tflite;1:images
mnasnet_0.50_224_1_metadata_1.tflite;1:input
mnasnet_0.75_224_1_metadata_1.tflite;1:input
mnasnet_1.0_128_1_metadata_1.tflite;1:input
mnasnet_1.0_160_1_metadata_1.tflite;1:input
mnasnet_1.0_192_1_metadata_1.tflite;1:input
mnasnet_1.0_224_1_metadata_1.tflite;1:input
mnasnet_1.0_96_1_metadata_1.tflite;1:input
posenet_mobilenet_float_075_1_default_1.tflite;1:sub_2 39
deeplabv3_1_default_1.tflite;1:sub_7
lite-model_arbitrary-image-stylization-inceptionv3_fp16_predict_1.tflite;1:style_image
mindspore_text_classification_tflite.tflite;1:base_input
ml_ocr_latin_pb2tflite.tflite;1:input_0 9
ml_location.tflite;1:inputs
bloom_new_detect.tflite;1:input
bloom_model_age_gender.tflite;1:input
bloom_isface.tflite;1:data
hiai_object_detect_814.tflite;1:normalized_input_image_tensor 10
hiai_object_tflite_graph_8bit.tflite;1:normalized_input_image_tensor
lma_tsec_shallow_channels16_ds2.1.1_model-best-f1.tflite;1:inputs
ml_video_edit_img_segment_adaptise_pb2tflite.tflite;2:backbone_features2,w 12
hiai_cv_labelDetectorModel_v3.tflite;2:input_0,input_1
ml_headpose_pb2tflite.tflite;3:input_1,batch_normalization_8/batchnorm/add,batch_normalization_1/batchnorm/add;1,64,64,3:16:16
ml_ei_headpose_pb2tflite.tflite;3:input_1,batch_normalization_8/batchnorm_1/add,batch_normalization_1/batchnorm_1/add;1,64,64,3:16:16
#lite-model_mobilebert_1_metadata_1.tflite's precision deteriorates in P50
lite-model_mobilebert_1_metadata_1.tflite;3:input_ids,input_mask,segment_ids 23
coco_ssd_mobilenet_v1_1.0.tflite
bolt_segment.pb 4
glasses
hat
isface
ml_bank_detect_0312_tmp 13
ml_face_div_parsing
ml_hardware_eyeclose
Mnet6_0312_extract_pay 6
pose_3d
hiai_face_RFB-Epoch-170-no-transpose
tracking
detect-deeper-halfdeeper-mbv1-shortcut-400-400_nopostprocess_simplified
hiai_face_detect_rfb
hiai_face_isface
hiai_face_landmark
hiai_face_pose_tuku
ml_hand_detection
ml_ocr_sfz_detect_0325_tmp
ml_hardware_liveness
ml_liveness_detect_landmark_tmp
ml_face_contour
2012_ATLANTA_1class_20190621_v4.x_nomean
ml_ocr_sfz_add_final_0325
ml_hardware_pose
ml_bank_recog
#2012_ATLANTA_10class_20190131_v4.0's precision deteriorates in P50
2012_ATLANTA_10class_20190131_v4.0 10
mnet 9
recognition 7
ml_face_landmark
model_hebing_3branch 34
hiai_cv_focusShootOCRModel_07
hiai_cv_focusShootOCRModel_03 11
hiai_cv_focusShootOCRModel_01 9
hiai_face_hat1
hiai_cv_focusShootOCRModel_04 6
hiai_cv_focusShootOCRModel_06 11
hiai_cpu_face_hat
hiai_video_seg
hiai_semantic_seg
hiai_human_seg 28
hiai_face_recognition_1 7
hiai_cpu_face_detect
hiai_cpu_face_attr 34
hiai_face_attr1 34
retinaface
deconvs_model
ml_location_scene_division 9
ml_tabel_recog
6c_seg_nomean_20200610
ml_video_edit_img_segment
ml_video_edit_video_segment_gauss_adaptis_part1
ml_video_edit_Mnet
ml_video_edit_detect_20211111
ml_video_edit_MnetN367_extract_1010_pay
ml_video_edit_person_divison_pic
ml_video_edit_reid
ml_video_edit_v10_best_model_nomean_20200723
inception-v2-9.onnx
ml_face_isface;1:data
efficientnet-lite4-11.onnx;1:images:0
mobilenetv2-7.onnx;1:data 9
densenet-9.onnx;1:data_0
squeezenet1.0-9.onnx;1:data_0
residual_distill_cifar10_bs_1.onnx;1:actual_input
residual_distill_cifar10_bs_32.onnx;1:actual_input
residual_distill_bs_1.onnx;1:actual_input
residual_distill_bs_32.onnx;1:actual_input 20
crnn_lite_lstm_v2.onnx;1:input;32,32,32,1
residual_distill_res34_cifar10_bs_1_update.onnx;1:actual_input
residual_distill_res50_cifar10_bs_1_update.onnx;1:actual_input
hdc_Image_Aesthetic_MTI_Aesthetic.onnx;1:input
hdc_resnet_1w_class.onnx;1:input.1
hdc_ocr_detect_tmp.onnx;1:actual_input_1
ml_facedetector.onnx;1:input
ml_ei_facedetection.onnx;1:input
mtk_emotions-d2012-75.onnx;1:input.1
mtk_detect_mbv1_640_480_nopostprocess_simplified_onnx.onnx;1:input;1,480,640,3
mtk_face_features_v2.onnx;1:input;1,256,192,3
simple_IPS_model_4D_input.onnx;1:pytorch_onnx
rpnt_pdr_conv2d_16_fixed_last.onnx;1:input
hdc_efficientnet_b3_1w_class.onnx;1:input.1
porseg_tmp.onnx;2:img,prev_mask
hiai_nlu_onnx_model_v1_0.onnx;3:input_ids,segment_ids,position_ids
ml_video_edit_makeup_mobilenetv203.onnx;1:input.1
Q888_CV_face_recognition_self.onnx;1:input
# ml_video_edit_hair_dyeing_migrate_v2_fix.onnx;4  precision deteriorates in P40
ml_motion_capture_spin_mobile_mv3_v3_57mm_sim.onnx;5:input,bbox,init_pose,init_shape,init_cam
ml_video_edit_dimming_tech_model_345000_color.onnx;2:input.18,1
Ireland_gaze_corrector.onnx;3:image,target_angle,strength 14
unet_model_reconstruct.pb;1:content;1,256,256,3
ml_video_edit_generate_filter.pb;1:lowres_input
inception_resnet_v2.pb;1:input;1,299,299,3 22
inception_v4.pb;1:input;1,299,299,3
mnasnet_1.0_224.pb;1:input
mnasnet_1.3_224.pb;1:input
